#!/bin/bash

# Mestres do Caf√© - Script de Execu√ß√£o de Testes
# Executa todos os tipos de testes com relat√≥rios detalhados

set -e  # Para execu√ß√£o em caso de erro

# Cores para output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configura√ß√µes
PROJECT_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")/../.." && pwd)"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
REPORTS_DIR="$PROJECT_ROOT/reports/tests/$TIMESTAMP"
COVERAGE_DIR="$PROJECT_ROOT/reports/coverage/$TIMESTAMP"

# Fun√ß√£o para logging
log() {
    echo -e "${BLUE}[$(date +'%Y-%m-%d %H:%M:%S')]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# Fun√ß√£o para verificar depend√™ncias
check_dependencies() {
    log "Verificando depend√™ncias..."
    
    # Verifica Python
    if ! command -v python3 &> /dev/null; then
        log_error "Python3 n√£o encontrado"
        exit 1
    fi
    
    # Verifica pip
    if ! command -v pip3 &> /dev/null; then
        log_error "pip3 n√£o encontrado"
        exit 1
    fi
    
    # Verifica pytest
    if ! python3 -c "import pytest" &> /dev/null; then
        log_error "pytest n√£o encontrado. Instalando..."
        pip3 install pytest pytest-cov pytest-html pytest-xdist
    fi
    
    # Verifica selenium para testes E2E
    if ! python3 -c "import selenium" &> /dev/null; then
        log_warning "Selenium n√£o encontrado. Testes E2E ser√£o pulados."
        SKIP_E2E=true
    fi
    
    log_success "Depend√™ncias verificadas"
}

# Fun√ß√£o para setup do ambiente
setup_environment() {
    log "Configurando ambiente de testes..."
    
    # Cria diret√≥rios necess√°rios
    mkdir -p "$REPORTS_DIR"
    mkdir -p "$COVERAGE_DIR"
    mkdir -p "$PROJECT_ROOT/logs"
    mkdir -p "$PROJECT_ROOT/tests/screenshots"
    
    # Define vari√°veis de ambiente
    export PYTHONPATH="$PROJECT_ROOT:$PYTHONPATH"
    export FLASK_ENV=testing
    export DATABASE_URL="sqlite:///:memory:"
    
    # Limpa cache do Python
    find "$PROJECT_ROOT" -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true
    find "$PROJECT_ROOT" -name "*.pyc" -delete 2>/dev/null || true
    
    log_success "Ambiente configurado"
}

# Fun√ß√£o para executar testes unit√°rios
run_unit_tests() {
    log "Executando testes unit√°rios..."
    
    cd "$PROJECT_ROOT"
    
    pytest tests/unit/ \
        --verbose \
        --tb=short \
        --cov=apps/api/src \
        --cov-report=html:"$COVERAGE_DIR/unit" \
        --cov-report=xml:"$COVERAGE_DIR/unit/coverage.xml" \
        --cov-report=term-missing \
        --html="$REPORTS_DIR/unit_tests.html" \
        --self-contained-html \
        --junitxml="$REPORTS_DIR/unit_tests.xml" \
        --maxfail=5 \
        -x
    
    local exit_code=$?
    
    if [ $exit_code -eq 0 ]; then
        log_success "Testes unit√°rios conclu√≠dos com sucesso"
    else
        log_error "Testes unit√°rios falharam (c√≥digo: $exit_code)"
        return $exit_code
    fi
}

# Fun√ß√£o para executar testes de integra√ß√£o
run_integration_tests() {
    log "Executando testes de integra√ß√£o..."
    
    cd "$PROJECT_ROOT"
    
    # Inicia banco de dados de teste
    export DATABASE_URL="sqlite:///test_integration.db"
    
    pytest tests/integration/ \
        --verbose \
        --tb=short \
        --cov=apps/api/src \
        --cov-report=html:"$COVERAGE_DIR/integration" \
        --cov-report=xml:"$COVERAGE_DIR/integration/coverage.xml" \
        --html="$REPORTS_DIR/integration_tests.html" \
        --self-contained-html \
        --junitxml="$REPORTS_DIR/integration_tests.xml" \
        --maxfail=3 \
        -x
    
    local exit_code=$?
    
    # Limpa banco de teste
    rm -f test_integration.db
    
    if [ $exit_code -eq 0 ]; then
        log_success "Testes de integra√ß√£o conclu√≠dos com sucesso"
    else
        log_error "Testes de integra√ß√£o falharam (c√≥digo: $exit_code)"
        return $exit_code
    fi
}

# Fun√ß√£o para executar testes E2E
run_e2e_tests() {
    if [ "$SKIP_E2E" = true ]; then
        log_warning "Pulando testes E2E (Selenium n√£o dispon√≠vel)"
        return 0
    fi
    
    log "Executando testes End-to-End..."
    
    cd "$PROJECT_ROOT"
    
    # Verifica se ChromeDriver est√° dispon√≠vel
    if ! command -v chromedriver &> /dev/null; then
        log_warning "ChromeDriver n√£o encontrado. Tentando instalar..."
        
        # Tenta instalar ChromeDriver automaticamente
        if command -v apt-get &> /dev/null; then
            sudo apt-get update
            sudo apt-get install -y chromium-chromedriver
        else
            log_error "N√£o foi poss√≠vel instalar ChromeDriver automaticamente"
            return 1
        fi
    fi
    
    # Inicia aplica√ß√£o em background para testes E2E
    log "Iniciando aplica√ß√£o para testes E2E..."
    cd apps/api
    python3 src/app.py &
    APP_PID=$!
    
    # Aguarda aplica√ß√£o inicializar
    sleep 5
    
    # Verifica se aplica√ß√£o est√° rodando
    if ! curl -s http://localhost:5005/api/health > /dev/null; then
        log_error "Aplica√ß√£o n√£o iniciou corretamente"
        kill $APP_PID 2>/dev/null || true
        return 1
    fi
    
    cd "$PROJECT_ROOT"
    
    # Executa testes E2E
    pytest tests/e2e/ \
        --verbose \
        --tb=short \
        --html="$REPORTS_DIR/e2e_tests.html" \
        --self-contained-html \
        --junitxml="$REPORTS_DIR/e2e_tests.xml" \
        --maxfail=2 \
        -s  # N√£o captura output para ver logs do Selenium
    
    local exit_code=$?
    
    # Para aplica√ß√£o
    kill $APP_PID 2>/dev/null || true
    
    if [ $exit_code -eq 0 ]; then
        log_success "Testes E2E conclu√≠dos com sucesso"
    else
        log_error "Testes E2E falharam (c√≥digo: $exit_code)"
        return $exit_code
    fi
}

# Fun√ß√£o para executar testes de performance
run_performance_tests() {
    log "Executando testes de performance..."
    
    cd "$PROJECT_ROOT"
    
    # Verifica se locust est√° dispon√≠vel
    if ! python3 -c "import locust" &> /dev/null; then
        log_warning "Locust n√£o encontrado. Instalando..."
        pip3 install locust
    fi
    
    # Executa testes de carga b√°sicos
    python3 tools/scripts/performance_test.py > "$REPORTS_DIR/performance_report.txt"
    
    local exit_code=$?
    
    if [ $exit_code -eq 0 ]; then
        log_success "Testes de performance conclu√≠dos"
    else
        log_warning "Testes de performance falharam ou n√£o puderam ser executados"
    fi
}

# Fun√ß√£o para executar an√°lise de c√≥digo
run_code_analysis() {
    log "Executando an√°lise de c√≥digo..."
    
    cd "$PROJECT_ROOT"
    
    # Verifica se flake8 est√° dispon√≠vel
    if ! command -v flake8 &> /dev/null; then
        log_warning "flake8 n√£o encontrado. Instalando..."
        pip3 install flake8 pylint bandit safety
    fi
    
    # An√°lise de estilo (flake8)
    log "Executando an√°lise de estilo..."
    flake8 apps/ --max-line-length=100 --exclude=migrations,venv \
        --format=html --htmldir="$REPORTS_DIR/flake8" || true
    
    # An√°lise de qualidade (pylint)
    log "Executando an√°lise de qualidade..."
    pylint apps/api/src/ --output-format=html > "$REPORTS_DIR/pylint_report.html" || true
    
    # An√°lise de seguran√ßa (bandit)
    log "Executando an√°lise de seguran√ßa..."
    bandit -r apps/api/src/ -f html -o "$REPORTS_DIR/security_report.html" || true
    
    # Verifica√ß√£o de depend√™ncias (safety)
    log "Verificando vulnerabilidades em depend√™ncias..."
    safety check --json > "$REPORTS_DIR/safety_report.json" || true
    
    log_success "An√°lise de c√≥digo conclu√≠da"
}

# Fun√ß√£o para gerar relat√≥rio consolidado
generate_consolidated_report() {
    log "Gerando relat√≥rio consolidado..."
    
    local report_file="$REPORTS_DIR/consolidated_report.html"
    
    cat > "$report_file" << EOF
<!DOCTYPE html>
<html>
<head>
    <title>Relat√≥rio de Testes - Mestres do Caf√©</title>
    <meta charset="UTF-8">
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .header { background: #2c3e50; color: white; padding: 20px; border-radius: 5px; }
        .section { margin: 20px 0; padding: 15px; border: 1px solid #ddd; border-radius: 5px; }
        .success { background: #d4edda; border-color: #c3e6cb; }
        .warning { background: #fff3cd; border-color: #ffeaa7; }
        .error { background: #f8d7da; border-color: #f5c6cb; }
        .metrics { display: flex; justify-content: space-around; margin: 20px 0; }
        .metric { text-align: center; padding: 10px; background: #f8f9fa; border-radius: 5px; }
        .links { margin: 10px 0; }
        .links a { margin-right: 15px; color: #007bff; text-decoration: none; }
        .links a:hover { text-decoration: underline; }
    </style>
</head>
<body>
    <div class="header">
        <h1>üè¢ Mestres do Caf√© - Relat√≥rio de Testes</h1>
        <p>Gerado em: $(date)</p>
        <p>Timestamp: $TIMESTAMP</p>
    </div>
    
    <div class="metrics">
        <div class="metric">
            <h3>Testes Unit√°rios</h3>
            <p id="unit-status">‚úÖ Executados</p>
        </div>
        <div class="metric">
            <h3>Testes Integra√ß√£o</h3>
            <p id="integration-status">‚úÖ Executados</p>
        </div>
        <div class="metric">
            <h3>Testes E2E</h3>
            <p id="e2e-status">‚úÖ Executados</p>
        </div>
        <div class="metric">
            <h3>An√°lise C√≥digo</h3>
            <p id="analysis-status">‚úÖ Executada</p>
        </div>
    </div>
    
    <div class="section">
        <h2>üìä Relat√≥rios Detalhados</h2>
        <div class="links">
            <a href="unit_tests.html">Testes Unit√°rios</a>
            <a href="integration_tests.html">Testes Integra√ß√£o</a>
            <a href="e2e_tests.html">Testes E2E</a>
            <a href="../coverage/$TIMESTAMP/unit/index.html">Cobertura Unit√°rios</a>
            <a href="../coverage/$TIMESTAMP/integration/index.html">Cobertura Integra√ß√£o</a>
            <a href="flake8/index.html">An√°lise Estilo</a>
            <a href="pylint_report.html">An√°lise Qualidade</a>
            <a href="security_report.html">An√°lise Seguran√ßa</a>
        </div>
    </div>
    
    <div class="section">
        <h2>üìà M√©tricas de Qualidade</h2>
        <ul>
            <li><strong>Cobertura de C√≥digo:</strong> Verificar relat√≥rios espec√≠ficos</li>
            <li><strong>Complexidade:</strong> Analisada via pylint</li>
            <li><strong>Seguran√ßa:</strong> Verificada via bandit</li>
            <li><strong>Depend√™ncias:</strong> Verificadas via safety</li>
        </ul>
    </div>
    
    <div class="section">
        <h2>üîß Comandos para Reproduzir</h2>
        <pre>
# Testes unit√°rios
pytest tests/unit/ --cov=apps/api/src

# Testes integra√ß√£o  
pytest tests/integration/

# Testes E2E
pytest tests/e2e/

# An√°lise completa
./tools/scripts/run_tests.sh
        </pre>
    </div>
    
    <div class="section">
        <h2>üìù Pr√≥ximos Passos</h2>
        <ul>
            <li>Revisar falhas nos testes</li>
            <li>Melhorar cobertura de c√≥digo</li>
            <li>Corrigir issues de qualidade</li>
            <li>Resolver vulnerabilidades de seguran√ßa</li>
        </ul>
    </div>
</body>
</html>
EOF
    
    log_success "Relat√≥rio consolidado gerado: $report_file"
}

# Fun√ß√£o para limpeza
cleanup() {
    log "Executando limpeza..."
    
    # Para processos em background
    pkill -f "python.*app.py" 2>/dev/null || true
    
    # Remove arquivos tempor√°rios
    rm -f test_*.db
    
    log_success "Limpeza conclu√≠da"
}

# Fun√ß√£o principal
main() {
    local start_time=$(date +%s)
    
    echo "üß™ MESTRES DO CAF√â - EXECU√á√ÉO COMPLETA DE TESTES"
    echo "=================================================="
    
    # Trap para limpeza em caso de interrup√ß√£o
    trap cleanup EXIT
    
    # Verifica argumentos
    local run_unit=true
    local run_integration=true
    local run_e2e=true
    local run_performance=false
    local run_analysis=true
    
    while [[ $# -gt 0 ]]; do
        case $1 in
            --unit-only)
                run_integration=false
                run_e2e=false
                run_analysis=false
                shift
                ;;
            --integration-only)
                run_unit=false
                run_e2e=false
                run_analysis=false
                shift
                ;;
            --e2e-only)
                run_unit=false
                run_integration=false
                run_analysis=false
                shift
                ;;
            --with-performance)
                run_performance=true
                shift
                ;;
            --no-analysis)
                run_analysis=false
                shift
                ;;
            --help)
                echo "Uso: $0 [op√ß√µes]"
                echo "Op√ß√µes:"
                echo "  --unit-only         Executa apenas testes unit√°rios"
                echo "  --integration-only  Executa apenas testes de integra√ß√£o"
                echo "  --e2e-only         Executa apenas testes E2E"
                echo "  --with-performance Inclui testes de performance"
                echo "  --no-analysis      Pula an√°lise de c√≥digo"
                echo "  --help             Mostra esta ajuda"
                exit 0
                ;;
            *)
                log_error "Op√ß√£o desconhecida: $1"
                exit 1
                ;;
        esac
    done
    
    # Execu√ß√£o dos testes
    check_dependencies
    setup_environment
    
    local overall_success=true
    
    if [ "$run_unit" = true ]; then
        if ! run_unit_tests; then
            overall_success=false
        fi
    fi
    
    if [ "$run_integration" = true ]; then
        if ! run_integration_tests; then
            overall_success=false
        fi
    fi
    
    if [ "$run_e2e" = true ]; then
        if ! run_e2e_tests; then
            overall_success=false
        fi
    fi
    
    if [ "$run_performance" = true ]; then
        run_performance_tests
    fi
    
    if [ "$run_analysis" = true ]; then
        run_code_analysis
    fi
    
    generate_consolidated_report
    
    local end_time=$(date +%s)
    local duration=$((end_time - start_time))
    
    echo "=================================================="
    echo "üèÅ EXECU√á√ÉO CONCLU√çDA"
    echo "Dura√ß√£o: ${duration}s"
    echo "Relat√≥rios: $REPORTS_DIR"
    
    if [ "$overall_success" = true ]; then
        log_success "Todos os testes passaram! ‚úÖ"
        exit 0
    else
        log_error "Alguns testes falharam! ‚ùå"
        exit 1
    fi
}

# Executa fun√ß√£o principal
main "$@"

